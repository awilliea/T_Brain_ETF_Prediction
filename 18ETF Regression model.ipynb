{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>20130102</td>\n",
       "      <td>台泥</td>\n",
       "      <td>38.95</td>\n",
       "      <td>39.1</td>\n",
       "      <td>38.65</td>\n",
       "      <td>39</td>\n",
       "      <td>6,374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1101</td>\n",
       "      <td>20130103</td>\n",
       "      <td>台泥</td>\n",
       "      <td>39.5</td>\n",
       "      <td>39.5</td>\n",
       "      <td>38.75</td>\n",
       "      <td>38.85</td>\n",
       "      <td>9,710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>20130104</td>\n",
       "      <td>台泥</td>\n",
       "      <td>39.4</td>\n",
       "      <td>39.45</td>\n",
       "      <td>38.6</td>\n",
       "      <td>39</td>\n",
       "      <td>8,682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1101</td>\n",
       "      <td>20130107</td>\n",
       "      <td>台泥</td>\n",
       "      <td>39.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>38.65</td>\n",
       "      <td>38.9</td>\n",
       "      <td>5,067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101</td>\n",
       "      <td>20130108</td>\n",
       "      <td>台泥</td>\n",
       "      <td>38.9</td>\n",
       "      <td>39.1</td>\n",
       "      <td>38.2</td>\n",
       "      <td>38.5</td>\n",
       "      <td>6,454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code      date                name   open   high    low  close       volume\n",
       "0  1101  20130102  台泥                  38.95   39.1  38.65     39        6,374\n",
       "1  1101  20130103  台泥                   39.5   39.5  38.75  38.85        9,710\n",
       "2  1101  20130104  台泥                   39.4  39.45   38.6     39        8,682\n",
       "3  1101  20130107  台泥                   39.1   39.1  38.65   38.9        5,067\n",
       "4  1101  20130108  台泥                   38.9   39.1   38.2   38.5        6,454"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"tsharep.csv\",encoding=' big5-hkscs ').rename(columns={'代碼':'code','日期':'date','中文簡稱':'name','開盤價(元)':'open','最高價(元)':'high','最低價(元)':'low','收盤價(元)':'close','成交張數(張)':'volume'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETF_data_processing(filepath):\n",
    "    ETFtable = pd.read_csv(filepath,encoding=' big5-hkscs ').rename(columns={'代碼':'code','日期':'date','中文簡稱':'name','開盤價(元)':'open','最高價(元)':'high','最低價(元)':'low','收盤價(元)':'close','成交張數(張)':'volume'})\n",
    "   \n",
    "    #processing data type \n",
    "    ETFtable['date'] = ETFtable['date'].map(lambda x:dt.datetime.strptime(str(x),'%Y%m%d'))\n",
    "#     ETFtable['week'] = ETFtable['date'].map(lambda x:x.isoweekday())\n",
    "    ETFtable['close'] = ETFtable['close'].map(lambda x:x if (type(x)==float) else float(x.replace(',','')) )\n",
    "    ETFtable['open'] = ETFtable['open'].map(lambda x:x if (type(x)==float) else float(x.replace(',','')) )\n",
    "    ETFtable['high'] = ETFtable['high'].map(lambda x:x if (type(x)==float) else float(x.replace(',','')) )\n",
    "    ETFtable['low'] = ETFtable['low'].map(lambda x:x if (type(x)==float) else float(x.replace(',','')) )\n",
    "    ETFtable['volume'] = ETFtable['volume'].map(lambda x:x if (type(x)==float) else float(x.replace(',','')) )\n",
    "    \n",
    "    return ETFtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>54.65</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.40</td>\n",
       "      <td>16487.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.90</td>\n",
       "      <td>55.05</td>\n",
       "      <td>54.65</td>\n",
       "      <td>54.85</td>\n",
       "      <td>29020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.85</td>\n",
       "      <td>54.85</td>\n",
       "      <td>54.40</td>\n",
       "      <td>54.50</td>\n",
       "      <td>9837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.55</td>\n",
       "      <td>54.55</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.25</td>\n",
       "      <td>8910.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>54.20</td>\n",
       "      <td>53.65</td>\n",
       "      <td>53.90</td>\n",
       "      <td>12507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code       date              name   open   high    low  close   volume\n",
       "0    50 2013-01-02  元大台灣50            54.00  54.65  53.90  54.40  16487.0\n",
       "1    50 2013-01-03  元大台灣50            54.90  55.05  54.65  54.85  29020.0\n",
       "2    50 2013-01-04  元大台灣50            54.85  54.85  54.40  54.50   9837.0\n",
       "3    50 2013-01-07  元大台灣50            54.55  54.55  53.90  54.25   8910.0\n",
       "4    50 2013-01-08  元大台灣50            54.00  54.20  53.65  53.90  12507.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ETFtable = ETF_data_processing('tetfp.csv')\n",
    "ETFtable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One day prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target ETF\n",
    "def extract_target_ETF(ETFtable,ETFcode):\n",
    "    ETF_target = ETFtable[ETFtable['code']==ETFcode].drop(['code','name'],axis = 1).groupby(['date']).sum()\n",
    "#     ETF_target = pd.concat([ETF_target,index_table],axis = 1)\n",
    "    \n",
    "    # move the target feature to the last column\n",
    "    t = ETF_target['close'].values\n",
    "    ETF_target.drop(['close'],axis=1,inplace = True)\n",
    "    ETF_target['close'] = t\n",
    "    \n",
    "    return ETF_target\n",
    "\n",
    "#data type\n",
    "def normalize_data(df):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    df_N = df.copy()\n",
    "    \n",
    "    for columnname in df_N.columns:\n",
    "        df_N[columnname] = min_max_scaler.fit_transform(df_N[columnname].values.reshape(-1,1))\n",
    "    \n",
    "    return df_N \n",
    "\n",
    "def denormalize(stock, normalized_value,columnname): \n",
    "    stock_price = stock[columnname].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "\n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    stock_price_N = min_max_scaler.fit_transform(stock_price)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new\n",
    "\n",
    "#load data\n",
    "def load_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns) \n",
    "    data = stock.as_matrix() \n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    result = []\n",
    "    \n",
    "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
    "        result.append(data[index: index + sequence_length]) # index : index + 20days\n",
    "    \n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0]) # 90% split\n",
    "    train = result[:int(row), :] # 90% date, all features \n",
    "    \n",
    "    x_train = train[:, :-1] #make the last day of train data as y_train\n",
    "    y_train = train[:, -1][:,-1] #the close price of the last day of every data \n",
    "    \n",
    "    x_test = result[int(row):, :-1] \n",
    "    y_test = result[int(row):, -1][:,-1]\n",
    "\n",
    "    x_train = x_train.reshape((x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
    "    x_test =  x_test.reshape((x_test.shape[0],x_test.shape[1]*x_test.shape[2]))\n",
    "     \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "# Model\n",
    "class LinearRegressionReg:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._dimension = 0\n",
    "\n",
    "    def fit(self, X, Y, lamb):  #calculate w\n",
    "        self._dimension = X.shape[1]\n",
    "        self._w = np.zeros((self._dimension,1))\n",
    "        self._lamb = lamb\n",
    "        self._w = np.linalg.inv(np.dot(X.T, X) + lamb*np.eye(self._dimension)).dot(X.T).dot(Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        result = np.dot(X, self._w)\n",
    "        return result\n",
    "    \n",
    "    def fiveday_predict(self,X,Y):\n",
    "        for i in range(5):\n",
    "            Y_predict = self.predict(X)\n",
    "    \n",
    "    def error(self, X, Y):  #squared error\n",
    "        Y_predict = self.predict(X)\n",
    "        return sum((Y_predict-Y)**2)/(len(Y)*1.0)            \n",
    "\n",
    "    def get_w(self):\n",
    "        return self._w\n",
    "\n",
    "    def print_val(self):\n",
    "        print (\"w: \", self._w)\n",
    "    \n",
    "    def score(self,X,Y,original_stock):\n",
    "        Y_predict = self.predict(X)\n",
    "        Y_predict_de = denormalize(original_stock,Y_predict,'close').reshape((Y.shape[0]))\n",
    "        Y_test_de = denormalize(original_stock,Y,'close').reshape((Y.shape[0]))\n",
    "        return sum(((Y_test_de-abs(Y_predict_de-Y_test_de))/Y_test_de)*0.5)/(len(Y_test_de)*1.0)\n",
    "\n",
    "# Picture\n",
    "def feature_importance(lr):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Weight')\n",
    "\n",
    "    plt.bar([_ for _ in range(len(lr.get_w()))],lr.get_w())\n",
    "    \n",
    "def feature_importance_scatter(lr,window,stock):\n",
    "    picture = [[_] for _ in range(window)]\n",
    "    picture_label = []\n",
    "    for i in picture:\n",
    "        picture_label += i*10\n",
    "    \n",
    "    xlabel = list(stock.columns)\n",
    "\n",
    "    # Scatter plot \n",
    "    trace = go.Scatter(\n",
    "        y = lr.get_w(),\n",
    "        x = xlabel*20,\n",
    "        mode='markers',\n",
    "        name = 'Importance',\n",
    "        marker=dict(\n",
    "            sizemode = 'diameter',\n",
    "            sizeref = 1,\n",
    "            size = 25,\n",
    "    #       size= feature_dataframe['AdaBoost feature importances'].values,\n",
    "            #color = np.random.randn(500), #set color equal to a variable\n",
    "            color = lr.get_w(),\n",
    "            colorscale='Portland',\n",
    "            showscale=True\n",
    "        ),\n",
    "        text = xlabel*20\n",
    "    )\n",
    "    data = [trace]\n",
    "\n",
    "    layout= go.Layout(\n",
    "        autosize= True,\n",
    "        title= 'Linear Regression Feature Importance on weight',\n",
    "        hovermode= 'closest',\n",
    "        xaxis= dict(\n",
    "            title= 'Feature name',\n",
    "    #         ticklen= 5,\n",
    "    #         zeroline= False,\n",
    "    #         gridwidth= 2,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title= 'Feature Importance',\n",
    "            ticklen= 5,\n",
    "            gridwidth= 2\n",
    "        ),\n",
    "        showlegend= False\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig,filename='scatter1')\n",
    "\n",
    "    # Scatter plot \n",
    "    trace = go.Scatter(\n",
    "        y = lr.get_w(),\n",
    "        x = xlabel*20,\n",
    "        mode='markers',\n",
    "        name = 'Day',\n",
    "        marker=dict(\n",
    "            sizemode = 'diameter',\n",
    "            sizeref = 1,\n",
    "            size = 25,\n",
    "    #       size= feature_dataframe['AdaBoost feature importances'].values,\n",
    "            #color = np.random.randn(500), #set color equal to a variable\n",
    "            color = picture_label,\n",
    "            colorscale='Portland',\n",
    "            showscale=True\n",
    "        ),\n",
    "        text = xlabel*20\n",
    "    )\n",
    "    data = [trace]\n",
    "\n",
    "    layout= go.Layout(\n",
    "        autosize= True,\n",
    "        title= 'Linear Regression Feature Importance on day',\n",
    "        hovermode= 'closest',\n",
    "        xaxis= dict(\n",
    "            title= 'Feature name',\n",
    "    #         ticklen= 5,\n",
    "    #         zeroline= False,\n",
    "    #         gridwidth= 2,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title= 'Feature Importance',\n",
    "            ticklen= 5,\n",
    "            gridwidth= 2\n",
    "        ),\n",
    "        showlegend= False\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig,filename='scatter2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One day prediction for 18 ETF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_day_prediction(ETF_list,window,lamb):\n",
    "    ETF_score = []\n",
    "    for ETF_code in ETF_list:\n",
    "        ETF_target = extract_target_ETF(ETFtable,ETF_code)\n",
    "        ETF_target_N = normalize_data(ETF_target)\n",
    "        X_train, y_train, X_test, y_test = load_data(ETF_target_N, window)\n",
    "\n",
    "        ### Model\n",
    "        lr = LinearRegressionReg()\n",
    "        lr.fit(X_train, y_train, lamb)\n",
    "\n",
    "        ### score\n",
    "        score = lr.score(X_test,y_test,ETF_target)\n",
    "        print(f'{ETF_code} average one day score is',score)\n",
    "        ETF_score.append(score)\n",
    "        \n",
    "    print('Total ETF one day price score is',sum(ETF_score))    \n",
    "    print('Average ETF one day price score is',sum(ETF_score)/18.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 average one day score is 0.4962552440648926\n",
      "51 average one day score is 0.495951881282426\n",
      "52 average one day score is 0.49376978013907724\n",
      "53 average one day score is 0.49543359935376463\n",
      "54 average one day score is 0.49673861951048187\n",
      "55 average one day score is 0.4971278209973724\n",
      "56 average one day score is 0.49722225889527605\n",
      "57 average one day score is 0.49628300750443083\n",
      "58 average one day score is 0.496891681977097\n",
      "59 average one day score is 0.4960521928040788\n",
      "6201 average one day score is 0.49439857990179104\n",
      "6203 average one day score is 0.496125098926445\n",
      "6204 average one day score is 0.4970685035802757\n",
      "6208 average one day score is 0.4960916651966915\n",
      "690 average one day score is 0.4970759507184719\n",
      "692 average one day score is 0.4968240960515666\n",
      "701 average one day score is 0.4968848123659525\n",
      "713 average one day score is 0.49664836998113193\n",
      "Total ETF one day price score is 8.932843163251224\n",
      "Average ETF one day price score is 0.49626906462506803\n"
     ]
    }
   ],
   "source": [
    "# 0 <= score <= 0.5\n",
    "ETF_list = [50,51,52,53,54,55,56,57,58,59,6201,6203,6204,6208,690,692,701,713]\n",
    "window = 20\n",
    "lamb = 1\n",
    "one_day_prediction(ETF_list,window,lamb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five day prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "def load_data_feature(stock, seq_len,feature,day=0):\n",
    "    amount_of_features = len(stock.columns) \n",
    "    data = stock.as_matrix() \n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    result = []\n",
    "    \n",
    "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
    "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
    "    \n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0]) # 90% split\n",
    "    train = result[:int(row), :] # 90% date, all features \n",
    "    \n",
    "    x_train = train[:, :-1] \n",
    "    y_train = train[:,-1,feature] \n",
    "\n",
    "    x_test = result[int(row):, :-1] \n",
    "    y_test = result[int(row):, -1,feature]\n",
    "\n",
    "    \n",
    "    x_train = x_train.reshape((x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
    "    x_test =  x_test.reshape((x_test.shape[0],x_test.shape[1]*x_test.shape[2])) #shape(127,20,6) --> (127,120)\n",
    "     \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "\n",
    "#transform the shape of features array into the shape of X data\n",
    "def shape_transfrom(features):\n",
    "    features_=[]\n",
    "    for i in range(features.shape[1]):\n",
    "        temp = np.array([])\n",
    "        for feature in features:\n",
    "            temp = np.hstack((temp,feature[i]))\n",
    "        features_ .append(temp)\n",
    "    \n",
    "    features_ = np.array(features_)\n",
    "    return features_\n",
    "\n",
    "\n",
    "def make_features_model_first(stock,seq_len,lamb):\n",
    "    amount_of_features = len(stock.columns)\n",
    "    models = []\n",
    "    errors = []\n",
    "    features = []\n",
    "    columns = stock.columns\n",
    "    \n",
    "    for i in range(amount_of_features): #load data and train\n",
    "        x_train ,y_train ,x_test,y_test= load_data_feature(stock,seq_len,i)\n",
    "        lr = LinearRegressionReg()\n",
    "        lr.fit(x_train,y_train,lamb)\n",
    "        models.append(lr)\n",
    "        errors.append(lr.error(x_test,y_test))\n",
    "        features.append(lr.predict(x_test))\n",
    "#         print(\"Eout of %s is %f\"%(columns[i],errors[i]))\n",
    "        \n",
    "    features_ = shape_transfrom(np.array(features))\n",
    "    \n",
    "    return [features_,models,x_test,y_test]\n",
    "\n",
    "def predict_features(x_test,model,amount_of_features):\n",
    "    errors = []\n",
    "    features = []\n",
    "    \n",
    "    for i in range(amount_of_features): #load data and train\n",
    "#         errors.append(lr.score(x_test,y_test))\n",
    "        features.append(model[i].predict(x_test))\n",
    "    features = np.array(features)\n",
    "    features_ = shape_transfrom(features)\n",
    "    \n",
    "    return features_ \n",
    "\n",
    "def fiveday_predict(stock,seq_len,lamb):\n",
    "    amount_of_features = len(stock.columns)\n",
    "    features,model,x_test,y_test = make_features_model_first(stock,seq_len,lamb)\n",
    "    y_predict = []\n",
    "    y_predict.append(features[:,-1]) #shape = (127,1)\n",
    "    length = x_test.shape[0]\n",
    "    \n",
    "    for day in range(4): \n",
    "        #add the prediction of features\n",
    "        x_test_temp = []\n",
    "        for i in range(length):\n",
    "            x_test_temp.append(np.concatenate((x_test[i],features[i])))\n",
    "        x_test = np.array(x_test_temp)[:,amount_of_features:] #still use the recent 20 days data\n",
    "\n",
    "        #Predict features\n",
    "        features_1 = predict_features(x_test,model,amount_of_features)\n",
    "        y_predict.append(features_1[:,-1]) #take the close price\n",
    "    return [np.array(y_predict),y_test]\n",
    "    \n",
    "def week_score(original_stock,stock,window,lamb):\n",
    "    y_predict ,y_test= fiveday_predict(stock,window,lamb)\n",
    "    \n",
    "    length = y_test.shape[0]\n",
    "    y_test = denormalize(original_stock,y_test,'close').reshape((length))\n",
    "    week_score_ = []\n",
    "    \n",
    "    for day in range(5):\n",
    "        y_test_temp = y_test[day:]\n",
    "        y_predict_temp = denormalize(original_stock,y_predict[day],'close').reshape((length))[:length-day]\n",
    "        temp = np.array(list(map(lambda x,y:((y-abs(x-y))/y)*0.5,y_predict_temp,y_test_temp)))\n",
    "        week_score_.append(temp[:length-4])\n",
    "    week_score_ = np.array(week_score_)\n",
    "    \n",
    "    week_score = []\n",
    "    for week in range(week_score_.shape[1]):\n",
    "        score = 0\n",
    "        for day in range(week_score_.shape[0]):\n",
    "            if (day == 0):\n",
    "                score += week_score_[day][week]*0.1\n",
    "            elif (day == 1):\n",
    "                score += week_score_[day][week]*0.15\n",
    "            elif (day == 2):\n",
    "                score += week_score_[day][week]*0.2\n",
    "            elif (day == 3):\n",
    "                score += week_score_[day][week]*0.25\n",
    "            elif (day == 4):\n",
    "                score += week_score_[day][week]*0.3\n",
    "        week_score.append(score)\n",
    "    \n",
    "    return [week_score,sum(week_score)/(len(week_score)*1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_day_prediction(ETF_list,window,lamb):\n",
    "    ETF_score = []\n",
    "    for ETF_code in ETF_list:\n",
    "        ETF_target = extract_target_ETF(ETFtable,ETF_code)\n",
    "        ETF_target_N = normalize_data(ETF_target)\n",
    "        \n",
    "        fiveday_score_array,fiveday_score = week_score(ETF_target,ETF_target_N,window,lamb)\n",
    "        print(f'{ETF_code} average Fiveday_score is ',fiveday_score)\n",
    "        ETF_score.append(fiveday_score)\n",
    "        \n",
    "    print('Total ETF five day price score is',sum(ETF_score))    \n",
    "    print('Average ETF five day price score is',sum(ETF_score)/18.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 average Fiveday_score is  0.4930098536508626\n",
      "51 average Fiveday_score is  0.49309392074687086\n",
      "52 average Fiveday_score is  0.4892714483033573\n",
      "53 average Fiveday_score is  0.49182808540422324\n",
      "54 average Fiveday_score is  0.4939981504727719\n",
      "55 average Fiveday_score is  0.4951226829745353\n",
      "56 average Fiveday_score is  0.494544467130304\n",
      "57 average Fiveday_score is  0.4932807138845685\n",
      "58 average Fiveday_score is  0.4949038788712295\n",
      "59 average Fiveday_score is  0.49405025882091713\n",
      "6201 average Fiveday_score is  0.49009156636214957\n",
      "6203 average Fiveday_score is  0.4925345057025705\n",
      "6204 average Fiveday_score is  0.49403797993481746\n",
      "6208 average Fiveday_score is  0.492577556526498\n",
      "690 average Fiveday_score is  0.495462016230729\n",
      "692 average Fiveday_score is  0.49451744681047505\n",
      "701 average Fiveday_score is  0.4957275157845913\n",
      "713 average Fiveday_score is  0.4942928949193936\n",
      "Total ETF five day price score is 8.882344942530864\n",
      "Average ETF five day price score is 0.49346360791838134\n"
     ]
    }
   ],
   "source": [
    "#0 <= score <= 0.5 \n",
    "ETF_list = [50,51,52,53,54,55,56,57,58,59,6201,6203,6204,6208,690,692,701,713]\n",
    "window = 20\n",
    "lamb = 1\n",
    "five_day_prediction(ETF_list,window,lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
